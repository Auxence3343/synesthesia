= Rapport d’avancement: groupe “6.4”
PACT groupe 6.4 (Synestes.IA)
ifdef::env-gitlab,env-browser[:outfilesuffix: .adoc]
:doctype: book
:stem: latexmath
:source-highlighter: coderay
:toc-title: Table des matières
:toc: macro
:sectnums:
:imagesdir: images


// Partie non numérotée
:sectnums!:
== « Synesthes.IA »

=== Membres du groupe

* BARANOVA, Mariia
* BENAÏSSA-LEJAY, Ilian
* DO THUAN, Céline
* FROMONT, Auxence
* KADDOURI-WISNIEWSKI, Lina
* KRIVCENKO, Aleksandrs
* MARACINE, Lucas

=== Tuteur

* PHAM, Germain

=== Encadrant génie logiciel

* HULCELLE, Marc

<<<

== Résumé du sujet choisi en français (PAN1)

*_Note: 15 lignes max_*

Décrire votre projet sans le scénariser : De quoi s’agit-il ? En quoi
cette idée est compatible avec le thème de PACT ? Qu’est-ce qu’il
permettrait de faire de façon générale.

== English Summary (PAN1)

*_Note : 15 lignes max, version anglaise du texte précédent_*

Ligula dapibus egestas. Donec sed velit ac lectus mattis sagittis.

In hac habitasse platea . Maecenas in ligula. Duis tincidunt
odio sollicitudin quam. Nullam non mauris. Phasellus lacinia, velit sit
amet bibendum euismod, leo diam interdum ligula, eu scelerisque sem
purus in tellus.

<<<

*Notes concenant le rapport*

Les différentes pages du document sont rédigées en utilisant le langage
AsciiDoc. Le squelette de rapport contient des exemples avec entre autres:

* des images,
* des liens,
* des équations.

La structure du rapport (parties, sections et la relation avec les
différents fichiers) se trouve dans le fichier courant.

**Prenez le temps** de supprimer le texte de remplissage et les sections non
utilisées pour l'instant. Vous pouvez par exemple commenter ces parties non
utilisées pour qu'elles n'apparaissent pas dans le document final. En Asciidoc,
il suffit de les précéder de deux slashs (`//`).

<<<
toc::[]
<<<

// On numérote le reste des sections
:sectnums:

== Étude d’antériorité et justification de la proposition (PAN1)

include::proposition/proposition.adoc[Description de la proposition]

include::proposition/etat-de-l-art.adoc[Description de l’état de l’art]

<<<

== Scénarios d’usage (PAN1)

include::scenario/scenario.adoc[Scénarios d’usage]

<<<

== Architecture du projet (PAN1)

include::architecture/schema.adoc[Schéma d’architecture]

include::architecture/interfaces.adoc[Description des interfaces]

include::architecture/sequence.adoc[Diagramme de séquence]

include::architecture/ihm.adoc[Interface utilisateur graphique]

<<<

== Organisation du projet (PAN1)

include::organisation/planification.adoc[Diagramme de planification temporel des tâches]

include::organisation/plan-tests.adoc[Plans de test (PAN2+)]

<<<

[bibliography]
== Bibliographie (PAN1+)

include::References.adoc[Bibliographie]

Bibliographie

Etat de l’art :

La synesthésie a toujours entretenu un rapport étroit avec l’art. Certains artistes synesthètes [0], dont Kandinsky [1][2], usaient des possibilités que leur permettait la synesthésie dans leur création artistique. De nombreuses expositions montraient ce que l’artiste pouvait entendre en peignant [2][3]. Ainsi, les spectateurs pouvaient « ressentir » les tableaux avec plus de sens ce qui constituait une expérience synethétique à petite échelle. Or, dans ces expositions, la musique créée pour accompagner les tableaux l’était par des musiciens humains [1][2][3] , ce qui pose comme limite la subjectivité de l’interprétation des œuvres du peintre par les musiciens, et la difficulté de produire la musique pouRefShannon : C. E. SHANNON, A Mathematical Theory of Communication, Reprinted with corrections from The Bell System Technical Journal, pages 379–423, 623–656, Vol. 27, 1948, http://sites.google.com/site/parthochoudhury/aMToC_CShannon.pdf
r chaque peinture en un temps raisonnable.

Pour automatiser ce processus, il est nécessaire de déterminer ce qui constitue les liens entre musique et peinture. Ainsi, on peut prendre comme premier critère les émotions ressenties à la lecture d’une peinture. Pour cela on peut se baser sur une analyse des couleurs de la peinture et les associer à des émotions spécifiques [4]. Ainsi, on utilise ce critère dans le choix de la musique. Cette voie a été explorée dans [5] : les auteurs de l’étude ont réalisé une application mobile qui décomposait une peinure en émotions ressenties à l’aide d’une analyse de couleurs, et associait ces émotions à des musiques qui sont choisies et classées à la main. La divergence avec notre projet réside dans le but de l’étude : les chercheurs travaillaient à proposer une musique pour accompagner la lecture d’un tableau, là où le nôtre est de reproduire un ressenti synesthésique du tableau, donc reproduire une identité musicale propre du tableau.

 Une autre possibilité est d’entraîner un reseau de neurones sur une base de tableaux classée par style, époque et émotions ressenties [6][7][8] comme ça a été fait dans [12]. Cela peut être fait par un apprentissage supervisé ou non supervisé [13]. Ces critères seront ensuite traduits en critères musicaux [5] (comme le style, le « mood », le rythme etc.) qui pourront être utilisés dans la création de la musique par une IA tierse [9][10][11].


Synesthesie et art :

[0] Article Wikipédia sur la Synesthésie, rubrique Synesthètes célèbres
 https://fr.wikipedia.org/wiki/Synesth%C3%A9sie
[1] Exposition Kandinsky au centre Pompidou, Serge Lasvignes, Google, Feb 10, 2021
https://blog.google/outreach-initiatives/arts-culture/discover-artist-who-could-hear-colors/amp/
[2]  Exposition Kandinsky au centre Pompidou,  par Donnia Ghezlane-Lala le 15 Février 2021
https://www.google.com/amp/s/www.konbini.com/amp/arts/le-centre-pompidou-vous-permet-decouter-les-peintures-et-couleurs-de-kandinsky/
[3]  Play a Kandinsky, Google
https://artsandculture.google.com/experiment/sgF5ivv105ukhA

Etudes scientifiques :

[5] System for matching paintings with music based on emotions, Taemin Lee, Hyunki Lim, Dae-Won Kim, Sunkyu Hwang, Kyunghyun Yoon
School of Computer Science and Engineering, Chung-Ang University
https://dl.acm.org/doi/10.1145/3005358.3005366
[4]A method for extracting emotion using colors comprise the painting image
Dongwann Kang Hyounoh Shim Kyunghyun Yoon
 https://core.ac.uk/download/pdf/153368581.pdf
[12] Deep learning approaches to pattern extraction and recognition in paintings and drawings: an overview
Giovanna Castellano, Gennaro Vessio 02 April 2021
https://link.springer.com/article/10.1007/s00521-021-05893-z
[13] Predicting and grouping digitized paintings by style using unsupervised feature learning
Eren Gultepe, Thomas Edward Conturo, MasoudMakrehchi
https://www.sciencedirect.com/science/article/pii/S1296207417301474
[14] Style classification and visualization of art painting’s genre using self-organizing maps
Sang-Geol Lee & Eui-Young Cha
https://link.springer.com/article/10.1186/s13673-016-0063-4

Base de données (peintures) :

[7] Base de données artemis
https://www.artemisdataset.org/
[6] Base de données Wikiartemotions
http://saifmohammad.com/WebPages/wikiartemotions.html
[8] Base de données kaggle
https://www.kaggle.com/datasets/ikarus777/best-artworks-of-all-time

Intelligence artificille (musique) :

[9] https://www.aiva.ai/
[10] https://www.ampermusic.com/
[11] https://openai.com/blog/jukebox/

<<<

== Annexes

include::annexes/modifications.adoc[Modifications (PAN2+)]

include::annexes/avancement.adoc[Avancement des modules]

include::annexes/moduleX.adoc[Avancement module X]

include::annexes/moduleY.adoc[Avancement module Y]
